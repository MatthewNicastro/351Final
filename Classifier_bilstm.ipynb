{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as td\n",
    "import torchtext\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  3759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a8d56ace50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences():\n",
    "    tokenizer = split_text # the function above is the function we will be using to tokenize the text\n",
    "    TEXT = torchtext.data.ReversibleField(sequential=True, tokenize=tokenizer, lower=True)\n",
    "    LABEL = torchtext.data.Field(sequential=False, use_vocab=False) # sequential and use_vocab=False since no text (binary)\n",
    "    QID = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "    train_datafields = [(\"qid\", None), (\"question_text\", TEXT), (\"target\", LABEL)]\n",
    "    train = torchtext.data.TabularDataset( # If we had a validation set as well, we would add an additional .splits(...)\n",
    "                        path=\"data/sample/training/train_train_sample_cleaned.csv\", # the root directory where the data lies\n",
    "                        format='csv',\n",
    "                        # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "                        skip_header=True, \n",
    "                        fields=train_datafields)\n",
    "    val_datafields = [(\"qid\", None),\n",
    "                     (\"question_text\", TEXT), (\"target\", LABEL)] \n",
    "    val = torchtext.data.TabularDataset( \n",
    "                path=\"data/sample/test/train_test_sample_cleaned.csv\",\n",
    "                format=\"csv\",\n",
    "                skip_header=True,\n",
    "                fields=val_datafields\n",
    "    )\n",
    "    test_datafields = [(\"qid\", QID),\n",
    "                       (\"question_text\", TEXT)]\n",
    "    test = torchtext.data.TabularDataset( \n",
    "                path=\"data/test_cleaned.csv\",\n",
    "                format=\"csv\",\n",
    "                skip_header=True,\n",
    "                fields=test_datafields\n",
    "    )\n",
    "    return TEXT, LABEL, train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT, LABEL, folds, test = prepare_sequences()\n",
    "TEXT, LABEL, train, val, test = prepare_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [11:43, 1.23MB/s]                               \n",
      "100%|█████████▉| 398632/400000 [00:40<00:00, 18837.44it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "TEXT.build_vocab(train, vectors=\"glove.6B.100d\")\n",
    "TEXT.build_vocab(val, vectors=\"glove.6B.100d\")\n",
    "TEXT.build_vocab(test, vectors=\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(\n",
    "     train, # we pass in the datasets we want the iterator to draw data from\n",
    "     batch_size=64, \n",
    "     sort_key=lambda x: len(x.question_text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "     sort_within_batch=False, # sorting would add bias\n",
    "     repeat=False \n",
    ")\n",
    "\n",
    "ngpu = 1  \n",
    "val_iter = Iterator(\n",
    "    val,\n",
    "    batch_size=64,\n",
    "    sort=False,\n",
    "    sort_within_batch=False,\n",
    "    repeat=False\n",
    ")\n",
    "\n",
    "test_iter = Iterator(\n",
    "    test,\n",
    "    batch_size=64,\n",
    "    sort=False,\n",
    "    sort_within_batch=False,\n",
    "    repeat=False\n",
    ")\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42c23026fb54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBiLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_linear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlin_layer_dropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBiLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# gives us access to nn.Module methods and attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# similar to word2vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlstm_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim, num_linear, num_lstm, bidirectional, lstm_dropout, lin_layer_dropout):\n",
    "        super(BiLSTM, self).__init__() # gives us access to nn.Module methods and attributes\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim) # similar to word2vec model\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=num_lstm, dropout=lstm_dropout, bidirectional=bidirectional)\n",
    "        self.linear_layers = []\n",
    "        self.lin_layer_dropout = lin_layer_dropout\n",
    "        if bidirectional == True:\n",
    "            scale = 2 # Twice as many units in case of bidirectional\n",
    "        else:\n",
    "            scale = 1\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim * scale, hidden_dim * scale))\n",
    "            self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim * scale, 2)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        out, _ = self.encoder(self.embedding(seq))\n",
    "        feature = out[-1, :, :] # Keep the hidden layer from the last LSTM iteration\n",
    "        print(feature.shape)\n",
    "        \n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature) \n",
    "            feature = F.relu(feature)\n",
    "            # feature = F.dropout(feature, p=self.lin_layer_dropout, training=True)\n",
    "            preds = self.predictor(feature) # Preds is current predictions at timestep t\n",
    "        \n",
    "        feature = F.relu(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        # return nn.Softmax(dim=1)(preds)\n",
    "        return nn.LogSoftmax(dim = 1)(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all network parameters\n",
    "nh = 500\n",
    "em_sz = 50\n",
    "nl = 1\n",
    "nlstm = 2\n",
    "bidirectional = True\n",
    "lstm_drop = 0.1\n",
    "lin_drop = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all training parameters\n",
    "num_epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BiLSTM(nh, em_sz, nl, nlstm, bidirectional, lstm_drop, lin_drop).cuda()\n",
    "lstm.apply(weights_init)\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_iter:\n",
    "    optimizer.zero_grad()\n",
    "    lstm.zero_grad()\n",
    "    predicted = lstm.forward(data.question_text.to(device).long())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "lr = 0.2\n",
    "optimizer = optim.SGD(lstm.parameters(), lr = lr, momentum=0.9)\n",
    "errors = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch={}\".format(epoch))\n",
    "    total_error = 0\n",
    "    progress = 0\n",
    "    for data in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        lstm.zero_grad()\n",
    "        predicted = lstm.forward(data.question_text.to(device).long())\n",
    "        loss = criterion(predicted.squeeze(), data.target.to(device).long())\n",
    "        total_error += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if progress % 100 == 0: \n",
    "            print(\"loss -> {}\".format(loss.item()))\n",
    "        progress += 1\n",
    "    print(\"Total Batch error={}\".format(total_error))\n",
    "    errors.append(total_error)\n",
    "torch.save(lstm.state_dict(),'bi_lstm_cleaned_v1.1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(113030, 50)\n",
       "  (encoder): LSTM(50, 500, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "  (predictor): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = BiLSTM(nh, em_sz, nl, nlstm, bidirectional, lstm_drop, lin_drop).cuda()\n",
    "lstm.load_state_dict(torch.load('bi_lstm_cleaned_v1.1.pt'))\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8737030632411067"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0\n",
    "batch_size = 64\n",
    "num_batches = 0\n",
    "for batch in val_iter:\n",
    "    actual = batch.target.to(device)\n",
    "    question = batch.question_text.to(device).long()\n",
    "    preds = lstm.forward(question)\n",
    "    actual = actual.cpu().detach().numpy()\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    preds = np.array([np.argmax(row) for row in preds])\n",
    "    total_correct = sum(actual == preds)\n",
    "    accuracy += total_correct\n",
    "    num_batches += 1\n",
    "accuracy / (num_batches * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission for kaggle\n",
    "predictions = {}\n",
    "for batch in test_iter:\n",
    "    qid = batch.qid\n",
    "    question = batch.question_text.to(device).long()\n",
    "    preds = lstm.forward(question)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    preds = np.array([np.argmax(row) for row in preds])\n",
    "    for idx, ID in enumerate(qid):\n",
    "        predictions[ID.item()] = preds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qid = pd.read_csv('test_qid.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = {'qid' : [], 'prediction' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qid.columns = ['indx', 'qid']\n",
    "for indx in test_qid.indx: \n",
    "    submission['qid'].append(test_qid.qid[test_qid.indx == indx].item())\n",
    "    submission['prediction'].append(predictions[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375806"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission['qid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ = pd.DataFrame.from_dict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
